# Accelerate Configuration for NEXA ML Training
# Generated for Render.com deployment
# Use: accelerate launch --config_file deployment/accelerate_config.yaml train_script.py

compute_environment: LOCAL_MACHINE
distributed_type: 'NO'  # Change to MULTI_GPU for multi-GPU instances
fp16: true  # Mixed precision for GPU
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
num_machines: 1
num_processes: 1  # Increase for multi-GPU
gpu_ids: all  # Use all available GPUs

# DeepSpeed configuration (for future scaling)
deepspeed_config:
  gradient_accumulation_steps: 4
  gradient_clipping: 1.0
  offload_optimizer_device: cpu
  offload_param_device: cpu
  zero_optimization:
    stage: 2  # ZeRO-2 for memory efficiency
    offload_optimizer:
      device: cpu
      pin_memory: true
    offload_param:
      device: cpu
      pin_memory: true
    allgather_partitions: true
    allgather_bucket_size: 2e8
    overlap_comm: true
    reduce_scatter: true
    reduce_bucket_size: 2e8
    contiguous_gradients: true

# FSDP configuration (alternative to DeepSpeed)
fsdp_config:
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_backward_prefetch_policy: BACKWARD_PRE
  fsdp_offload_params: false
  fsdp_sharding_strategy: 1  # FULL_SHARD
  fsdp_state_dict_type: FULL_STATE_DICT
  fsdp_transformer_layer_cls_to_wrap: null

# Memory optimization
mixed_precision: fp16
gradient_checkpointing: true
gradient_accumulation_steps: 4

# CPU-specific settings (for Render free tier)
cpu: false  # Set to true for CPU-only instances
cpu_offload: true  # Offload to CPU when GPU memory is tight

# Logging
log_with: tensorboard  # Options: tensorboard, wandb, comet_ml, none
logging_dir: ./logs

# Environment-specific overrides for Render
downcast_bf16: false  # Render GPUs may not support bf16
tpu: false  # No TPU on Render
